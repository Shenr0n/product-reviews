version: '3.8'

services:

# Zookeeper service
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    hostname: zookeeper
    container_name: zookeeper
    environment:
      #client port is for the kafka brokers which are clients of zookeeper, used to communicate with zookeeper
      ZOOKEEPER_CLIENT_PORT: 2181
      #Heartbeat time in ms
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  broker1:
    image: confluentinc/cp-kafka:7.3.0
    hostname: broker1
    container_name: broker1
    ports:
      - "9092:9092"
    # First zookeeper should start
    depends_on:
      - zookeeper
    environment:
      #unique id for each kafka broker
      KAFKA_BROKER_ID: 1
      #where the broker can connect with zookeeper
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      #internal and external connections with different ports but same PLAINTEXT (unencrypted TCP) protocol.
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      #29092 is for access by kafka brokers within the containers, 9092 is for external host access
      #kafka listens on the following listeners
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      #how clients can connect and access the broker in cluster
      #each broker advertises itself with hostname and localhost
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker1:29092,PLAINTEXT_HOST://localhost:9092
      #topic replication for fault tolerance
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      #to prevent errors due to automatic creation of topics within the cluster
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"

  broker2:
    image: confluentinc/cp-kafka:7.3.0
    hostname: broker2
    container_name: broker2
    ports:
      - "9093:9093"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29093,PLAINTEXT_HOST://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker2:29093,PLAINTEXT_HOST://localhost:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"

  broker3:
    image: confluentinc/cp-kafka:7.3.0
    hostname: broker3
    container_name: broker3
    ports:
      - "9094:9094"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29094,PLAINTEXT_HOST://0.0.0.0:9094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker3:29094,PLAINTEXT_HOST://localhost:9094
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"

  producer:
    build:
      # To use Dockerfile and files inside the folder specified in the context to create the microservice
      context: ./producer
    container_name: kafka-producer
    volumes:
    # mount local directory into container
      - ./input:/app/input
    depends_on:
      - broker1
    networks:
      - default

# Consumer
  spark:
    build:
      context: ./spark_consumer
    container_name: spark
    depends_on:
      - broker1
    volumes:
    # mount output directory into container for writing
      - ./output/product_reviews:/opt/output
